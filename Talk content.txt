Event-Driven Systems Backed By MongoDB
    Привет!
    
    Я очень рад, что имею возможность выступить тут перед вам и поделиться опытом построения Event-Driven системы с использованием MongoDB.

    Меня зовут Андрей, я platform инженер в компании, бизнес которой строится на записи видео спортивных событий, сборе статистик и предоставлении удобного доступа к этим данным. В мои обязанности, помимо прочего, входит построение надежной и масштабируемой платформы для наших клиентов.

    В этом докладе я расскажу том, что такое Event-Driven системы, какие вызовы и подводные камни ждут разработчиков, об ограничениях и преимуществах MongoDB. Я подробно остановлюсь на механизме репликации MongoDB, на том, как реконструировать события из CRUD операций, о новом API, которое появилось для этого в MongoDB 3.6 (и которое было значительно доработано в MongoDB 4.0). Примеры буду в консоли и на .NET Core.

Who Am I And Why I Am Giving This Talk
    I am a platform engineer at Synergy Sports Technologies and one of my responsibilities is to make sure we have scalable and reliable data platform for variety of our clients.
    At some point it became obvious that we cannot perform massive computations with different complex domain rules involved on every request from client apps because we wanted our APIs to be performant and responsive. For certain workloads it made much more sense to execute some logic asynchronously as a reaction to the state change in a system. For example recalculate baseball game statistics on every game event that is logged by our game loggers. Also our database engine is MongoDB which had no support for ACID transactions, which mean if we persisted an update for one entity and error happened before we persisted an update to another one involved in the process there was a risk to leave a system in an inconsistent state.
    We decided to go for Event-Driven approach when every state modification raises an event that other subsystems can react on it and do what they want to do with that knowledge.
    We build such system and run it it production for almost a year, so it is proven to be reliable and efficient under our workloads and I want to share some of the challenges and considerations we've been facing during the implementation and running the system in production.

    





    

What Is The Event-Driven Architecture All About
    What is event-driven architecure.

Why distributed transactions are not an option
    Not supported by No-SQL databases and message brokers.

Atomic state changes in microservices and event publishing.

    In order to be reliable, an application must atomically update state and publish corresponding event. It cannot use a distributed transaction that spans the database and the message broker. Instead, it must use one of the patterns listed below.

    - Database triggers
        Trigger can be configured to insert event into Events table on state changes in one or multiple tables.
        Personally I have strong opinion that persistence mechanism must be dumb and avoid any domain-related logic. So this approach was not even considered.
    - Application events (Outbox)
        With this approach application persists the state and the event in single atomic transaction. Asynchronous thread or a process reads events from Events tables and publishes events to a message broker. Very valid approach in SQL databases and some No-SQL databases with support for ACID transactions.
        We used Mongo 3.4 back then and had no option for atomic transactions so we couldn't go with this approach.
        Mongo 4.0 introduce support for transaction but they come at a cost.
        <insert quote from mongo db docs regarding performance>
        There are better ways.
    - Transaction log tailing
        Place drawbacks to the slide and explain that I am going to tackle some of the drawbacks.
    - Event Sourcing
        I guess Event Sourcing is becoming mainstream these days. Some teams leverage power of it and many struggling with it. Good part of this approach is that the state of the entity is represented by the series of events each of which represents an atomic change to the state. Events are stored to the Event Store. Which allows reading all events the belong to an entity to reconstitute the state. Event Store also can act as a message broker with Pub/Sub mechanism. It means it can dispatch persisted events to other services or consumers.
        In our case Event Store was not an option because we had large system that relied on MongoDB as a persistence mechanism and it would have been huge effort to make all entities event-sourced. Also for many entities it is redundant so we started to look at alternatives.

Tailing the Oplog

    - Prior mongo 3.6 (which was our case as we used 3.4 and couldn't upgrade to 3.6 because of the issue that affected us).
    - Mongo 3.6 change stream subscription to every single collection of interest.
    - Mongo 4.0+ subscribe to entire database with change stream subscription and filter only collections that we are interested in.

Proc and cons of tailing Oplog

Flaws of change stream 3.6.
    - Losing some events due to flaws in resume-ability when changes dont happen too often and position is removed from the oplog.
    - Majority read concern which will case breakage if secondary go down in 2 nodes + Arbiter setup (our case).

Change stream 4.0+ is a way to go for deployments with 3+ data-bearing nodes.

Demo of the Oplog tailing.

Demo of the event emitter.

Demo of the state changes via custom domain events.

Slide for Event ordering. Indexes for timestamp and event type.

Demo of the event handling.

Slide for the concurrent event processing.

Slide for using Kafka and reasons when to use it.

Demo of .NET Core 2.1 Generic Host.




function tail() {
    var entry = db.oplog.rs.find().sort({$natural: -1}).limit(1).next();
    var ts = entry.ts;
    for(;;) {
        var commandResult = db.runCommand({
            find: "oplog.rs",
            filter: {"ts" : {$gt: ts}},
            tailable: true,
            awaitData: true,
            oplogReplay: true
        });
        new DBCommandCursor(db, commandResult).forEach(d => {
            ts = d.ts;
            printjson(d);
        });
    }
}

TODO: Mention takeaways 2 members - oplog, 3.6 - oplog. 4.0 and 3+ members - changestream.

TODO: Create a QR code with a link to demos.

Лозунг:
    Атомарное изменение делает ваши данные консистентными