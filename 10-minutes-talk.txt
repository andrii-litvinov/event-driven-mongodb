Основная мысль:
    Ключевым аспектом построения Event-Driven систем является атомарное сохранение состояния и публикация события, которое описывает это изменение.

Основы:
    - Пользователи хотят работать с надежными системами
    - Если произойдет сбой при сохранении состояния или при публикации события система перейдет в неконсистентное состояние.

Выводы/следствия:
    - Чтобы гарантировать консистентность состояния необходимо понять как этого можно добиться.

Действие:
    - Используйте Oplog напрямую или Change Stream для публикации событий.


5 секунд:
    Операция сохранения изменения состояния и публикации события должна быть атомарной.

1 минута:
    Давайте представим систему, состоящую из двух независимых подсистем. Допустим, в одной подсистеме изменяется состояние. Это изменение состояния нужно сообщить другой подсистеме. Обычно, для того, чтобы сообщить изменение состояния используют специальный вид сообщений - события. Одна подсистема публикует событие в брокер сообщений, а другая подсистема слушает события, которые там появляются, и на них реагирует. Если в первой подсистеме после изменения состояния произойдет сбой и событие не будет опубликовано - вторая подсистема никогда про это событие не узнает. Система окажется в неконсистентном состоянии. Возможно, какой-то критический процесс не будет завершен. Или никогда не начнется. Система будет ненадежна. Чтобы гарантировать надежность системы, операция сохранения изменения состояния и публикации события должна быть атомарной.

10 Минут:
    Прочитав тему доклада и, возможно, аннотацию, вы спросите: "А что же такое Event-Driven система?". Давайте разберемся и определимся с терминами. Представьте себе систему, состоящую из нескольких независимых компонентов или подсистем, которые существуют для решения бизнес-задачи. Чтобы выполнить бизнес-задачу, каждая подсистема должна совершить определенные действия. Каждой из подсистем нужно как-то понимать какое действие и когда нужно совершить. Под Event-Driven системами мы будет понимать такие системы, которые реагируют на изменение состояния системы для выполнения нужного действия. Такие системы еще называют реактивными.

    Возникает вопрос: Как одна подсистема узнает об изменении состояния другой подсистемы? Обычно для этого используют события. Событие - это специальный вид сообщения, которое представляет собой факт изменения состояние системы. У каждого события есть название или тип, который описывает природу изменения, обычно в прошедшем времени. Например, OrderPlaced, SupervisorAssigned, AccountDebited. Событие содержит минимальный набор данных, чтобы описать изменение состояния. Компонент, в котором происходит изменение состояния публикует событие, которое описывает это изменение, в брокер сообщений. Остальные компоненты, которые заинтересованы в этом изменении подписываются на эти события в брокере сообщений и реагируют на них выполняя необходимые действия.

    Давайте представим ситуацию, когда в первой подсистеме изменяется состояние, изменения записываются в базу и происходит сбой. При этом событие опубликовать не удается. В таком случае другие подсистемы никогда не узнают об этом событии и бизнес-процесс никогда не завершится. Система окажется в неконсистентном состоянии. Система будет ненадежной. Чтобы гарантировать надежность системы, операция сохранения состояния и публикации события должна быть атомарной.

    Рассмотрим способы атомарно сохранить изменение и опубликовать событие. Сразу оговорюсь, очевидную на первый взгляд Распределенную транзакцию или Two Phase Commit мы не рассматриваем по раду причин. Во-первых, координация транзакций существенно уменьшает пропускную способность системы и поэтому не применима в высоко-нагруженных системах. Во-вторых, многие брокеры сообщений просто не поддерживают распределенные транзакции.

    Наверное, самый простой и гибкий вариант - использовать Event Sourcing. При этом подходе состояние сущности моделируется как набор событий, которые происходили с сущностью. Чтобы восстановить актуальное состояние необходимо поочередно применить все события. При этом, Event Store - это база данных, специально спроектированная чтобы хранить события. И она в то же время является брокером сообщений. Выходит, изменяя состояние посредством события мы одновременно и публикуем сообщение чем и добиваемся необходимой нам атомарности. Я не буду подробно останавливаться на теме Event Sourcing'a, но, если кому-то интересно, - найдите меня после доклада, пообщаемся.
    
    Второй вариант часто известен под названием Event (или Message) Outbox. Этот подход применим для хранилищ данных поддерживающих ACID транзакции. Суть подхода заключается в том, что изменения состояния сущности и событие записываются в базу в одной транзакции. Событие записывается в специальную таблицу из которой асинхронный процесс потом вычитывает эти события и отправляет в брокер сообщений.
    <quote from mongo db docs regarding performance>

    Третий подход - использование триггеров в базе данных. Триггер срабатывает, когда данные в базе изменяются и он может эти изменения каким-то образом преобразовать в событие и записать в таблицу событий. Недостаток этого подхода в том, что из сырых измененных данных сложно понять и сформировать конкретные типы событий отражающие операции предметной области.

    Четвертый вариант называется Transaction Log Tailing. Во многих базах данных есть механизм репликации. Идея подхода заключается в том, чтобы читать данные из этого протокола и публиковать события сформированные из этих данных. Фактически, сервис, который читает данные из протокола репликации можно представить как еще одну реплику, которая подписана на изменения. Преимущество этого подхода - гарантия атомарности изменения состояния и публикации события. Не нужно думать в приложении о публикации события. Недостаток, как и в предыдущем варианте - сырые данные порой сложно выразить в виде осмысленных событий, но я покажу как с этим можно работать. Еще один недостаток, что в каждой БД этот протокол реализован по-разному и под каждую БД нужно создавать свое решение.
    
    У нас в системе на тот момент использовалась MongoDB 3.4 и только-только вышла MongoDB 3.6 с новым API Change Streams. Очевидно было, что нужно использовать механизм репликации для генерации событий и нужно было определиться с API. Выбор стоял между проверенным подходом чтения напрямую из Oplog и новым многообещающим Change Streams. Давайте подробнее рассмотрим преимущества и недостатки каждого.

    Oplog tailing
        Преимущества
            Надежный, проверенный годами механизм, используемый в production такими компаниями, как Stripe
            Возможно реализовать writeConcern=1, т.е. генерить событие сразу, а не ждать когда операции реплицируется на второстепенные ноды
        Недостатки
            Приватный, низкоуровневый протокол без доступной документации
            Приходится выискивать информацию по крупицам в интернете
            Протокол может поменяться в новой версии
            Более сложная реализация, если нужен writeConcern=Majority
            Еще сложнее, если используется шардинг. К счастью, это был не наш случай

    Change Streams
        Преимущества
            API позволяет меньшими усилиями реализовать задачу
            API зафиксирован, а значит будет развиваться и работать, как ожидается, даже если приватный протокол будет претерпевает изменения
            Использует writeConcern=Majority, т.е. гарантирует, что событие будет опубликовано только после того, как операция реплицировалась, т.е. Durable
        Недостатки
            Новое API, которое в production еще мало кем используется и может содержать баги
            Поддерживает только writeConcern=Majority
            Позволяет подписаться на Change Events только одной коллекции на соединение. Если нужно мониторить больше коллекций - нужно использовать больше соединений

    В долгосрочной перспективе Change Streams выглядел более привлекательно и первый прототип мы реализовали на нем. В целом получилось довольно прилично, но мы столкнулись со следующими проблемами:
        Большинство подписок работали нормально, но 1-2 постоянно отваливались по непонятной на тот момент причине. И ошибка была такая, что переподписаться на изменения было нельзя. Нужно было создавать подписку сначала и это могло приводить к потере данных их-за пропущенных операций.
        Так как в породакшене трудилась MongoDB 3.4, ее нужно было обновить до MongoDB 3.6. После обновления выяснилось, что в 3.6.2 была бага, которая нас серьезно афектила и пришлось откатываться до 3.4. При этом "что-то пошло не так" и SECONDARY перманентно отвалилась. Из-за наших объемов данных процесс добавления SECONDARY в кластер занял два с половиной дня. Мы используем конфигурацию 2 Data-bearing nodes + Arbiter и writeConcern=1. И стало очевидно, что даже если мы решим подождать фикс, использовать Change Stream мы не можем, така как это API поддерживает только writeConcern=Majority. Т.е. если бы у нас опять отвалилась нода мы бы в худшем случае несколько дней были бы без событий, что было, конечно недопустимо.

    Отсюда,

        Правило #1: Если у вас конфигурация primary-secondary-arbiter (PSA) используйте Oplog tailing.

        Правило №2: Если у вас MongoDB 3.6, используйте Oplog tailing. (объяснить почему)